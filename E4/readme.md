# 영화리뷰 텍스트 감성분석하기



## 학습목표

- 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정을 이해한다.
- RNN의 특징을 이해하고 시퀀셜한 데이터를 다루는 방법을 이해한다.
- 1-D CNN으로도 텍스트를 처리할 수 있음을 이해한다.
- IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성분류 실습을 진행한다.



## 텍스트 감정분석 연습

- 텍스트는 숫자 행렬로 변환할 필요가 없다.

- 텍스트에는 입력 순서가 중요하다.

- 숫자:단어 의 딕셔너리 형태로 사전을 만들거나, 기존 사전에 특정단어 추가

- 컴퓨터가 숫자만 계산가능하므로 key, value의 순서 바꿔줌

- 인코더 생성 : 시작단어("<BOS>") + 문장 을 숫자로 된 리스트화

- 디코더 생성 : 숫자화된 리스트를 다시 문장으로 복구, 모르는 단어는 "<UNK>"

- 임베딩 : 숫자화 된 단어를 몇차원의 벡터로 나타낼지 결정, 문장의 길이는 각각이지만 컴퓨터가 계산할 수 있게 통일해야 하므로 패딩작업 진행

- pad_sequences 이용 문장앞이나 뒤에 패딩진행(''<PAD>")

- 시퀀스데이터 학습가능한 RNN, 1D CNN, GlobalMaxPooling1D으로 학습진행(하나의 특징만 추출 - 긍, 부정평가), 

  input_shape = (None,) 모든차원 받아들일 수 있음



## IMDB 영화리뷰 감성분석 연습

* 50000개의 데이터 중 25000개 사용(긍정1, 부정0)
* 단어는 10000개 사용 (imdb.get_word_index()로 가져올수 있음)
* key, value 위치 바꿔준 후, 문장의 평균길이를 평균, 최대값, 표준편차등 이용, 임베딩을 위해 어느정도 길이로 문장을 자를지 결정
* 최대길이 기준으로 문장의 중요정보가 뒤에 있다 생각하고 앞을 패딩으로 채운 후(pad_sequence) 
* 수치화된 단어를 차원을 증가시켜 벡터화(embedding)
* 데이터를 train, test로 분리후 학습 진행
* 학습결과 확인 후 loss, val_loss 확인통해 overfitting 개선하여 모델 도출
* 임베딩된 단어와 벡터가 유사한 단어는 뜻이 유사한가? 추가 실험



## 네이버 영화리뷰 감성분석

* 20만개 데이터 사용(3/1)
* 가공이 안되어있는 데이터이므로 직접 가공해야 함
  * 중복치 제거, 결측치 제거
  * 한국어 토크나이저로 토큰화
  * 불용어 제거, 사전구성
  * 사전 만들기
* 적절한 길이 구해서 임베딩할 수 있게 padding
* 데이터 분할(train/val)
* 학습, 결과 시각화
* 임베딩 레이어의 분석



# 소감

아직은 자연어 부분이 전처리가 더 많어서 어렵다.  모델의 성능을 개선하는 방향으로 해야하지만 하드웨어, 소프트웨어의 문제때문에 추가적인 실습엔 어려움을 많이 겪었다. 데이터가 많아서 적은 epoch으로도 val_data가 금방 과적합에 이른거 같다.



