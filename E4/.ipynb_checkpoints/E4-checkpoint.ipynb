{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화리뷰 텍스트 감성분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정을 이해한다.\n",
    "\n",
    "* RNN의 특징을 이해하고 시퀀셜한 데이터를 다루는 방법을 이해한다.\n",
    "\n",
    "* 1-D CNN으로도 텍스트를 처리할 수 있음을 이해한다.\n",
    "\n",
    "* IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성분류 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 감정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 감정분석의 유용성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SNS 등에서 얻을 수 있는 광범위한 분량의 텍스트 데이터는 소비자들의 개인적, 감성적 반응이 잘 담겨있을 뿐만 아니라 실시간 트렌드를 빠르게 반영할 수 있는 데이터이다.\n",
    "* 텍스트 감성분석 접근법  \n",
    "-기계학습 기반  \n",
    "-감성사전 기반\n",
    "* 사전 기반의 감성분석이 기계학습 기반 접근법 대비 가지는 한계점  \n",
    "-분석 대상에 따라 같은 단어지만 반대의 극성을 가지는 가능성에 대응하기 어려움  \n",
    "-긍정과 부정의 원인이 되는 대상의 속성 기반 감정분석이 어려움\n",
    "* 텍스트에 감성분석 기법을 적용하면 데이터를 정형화하여 유용한 의사결정 보조자료로 사용 가능\n",
    "* 자연어 처리의 가장 대표적인 기법 : 워드 임베딩(Word Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 데이터의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텍스트는 숫자 행렬로 변환할 필요가 없다.\n",
    "* 텍스트에는 입력 순서가 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트를 숫자로 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'hungry']\n",
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'like', 5: 'hungry', 6: 'so', 7: 'apple', 8: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮기기\n",
    "sentences=['i am hungry', 'i like apple', 'i am so happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개기\n",
    "word_list = 'i am hungry'.split()\n",
    "print(word_list)\n",
    "\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워보자. 순서는 중요하지 않다.\n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어준다.\n",
    "index_to_word[0]=\"<PAD>\"  # 패딩용 단어\n",
    "index_to_word[1]=\"<BOS>\"  # 문장의 시작지점\n",
    "index_to_word[2]=\"<UNK>\"  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]=\"i\"\n",
    "index_to_word[4]=\"like\"\n",
    "index_to_word[5]=\"hungry\"\n",
    "index_to_word[6]=\"so\"\n",
    "index_to_word[7]=\"apple\"\n",
    "index_to_word[8]=\"happy\"\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'like': 4, 'hungry': 5, 'so': 6, 'apple': 7, 'happy': 8}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수\n",
    "# 단, 모든 문장은 <BOS>로 시작\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index[\"<BOS>\"]]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 2, 5], [1, 3, 4, 7], [1, 3, 2, 6, 8]]\n"
     ]
    }
   ],
   "source": [
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like hungry\n"
     ]
    }
   ],
   "source": [
    "# encode된 벡터를 decode하여 다시 원래 텍스트 데이터로 복구하는 함수\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else \"<UNK>\" for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i <UNK> hungry', 'i like apple', 'i <UNK> so happy']\n"
     ]
    }
   ],
   "source": [
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 레이어의 등장  \n",
    "https://wikidocs.net/64779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 01:32:33.237172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 01:32:35.621589: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-03 01:32:35.623656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-03 01:32:35.690860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:35.691808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2021-09-03 01:32:35.691852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-03 01:32:35.694442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-03 01:32:35.694508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-03 01:32:35.696818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-03 01:32:35.697187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-03 01:32:35.699472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-03 01:32:35.700300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-03 01:32:35.703394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-03 01:32:35.703569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:35.704146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:35.704594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-03 01:32:35.704633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-03 01:32:36.097267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-03 01:32:36.097304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-03 01:32:36.097310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-03 01:32:36.097530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:36.097923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:36.098282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:36.098600: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-09-03 01:32:36.098626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 5094 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)\n",
      "2021-09-03 01:32:36.098978: I "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 651888285197600927,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5341607360\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10833313342764822800\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25796/3560268247.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n"
     ]
    }
   ],
   "source": [
    "# Embedding\n",
    "vocal_size = len(word_to_index)\n",
    "word_vector_dim = 4\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocal_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequence를 통해 word_vector를 모두 일정길이로 맞춰줌\n",
    "# embedding layer의 input이 될 수 있음에 주의\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "#output = embedding(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 2, 5], [1, 3, 4, 7], [1, 3, 2, 6, 8]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_encoded_sentences(sentences, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 3, 2, 5]), list([1, 3, 4, 7]), list([1, 3, 2, 6, 8])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행해 보니 에러가 발생합니다. 왜 그럴까요?\n",
    "\n",
    "주의해야 할 점이 있습니다. Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 합니다. \n",
    "raw_inputs의 3개 벡터의 길이는 각각 4, 4, 5입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 2 5 0]\n",
      " [1 3 4 7 0]\n",
      " [1 3 2 6 8]]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow에서는 keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 \n",
    "# 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00935122 -0.01823239 -0.01778016 -0.04506478]\n",
      "  [-0.01417989 -0.00534748 -0.0290529   0.00897658]\n",
      "  [-0.02972589 -0.02586786  0.02854559  0.03632262]\n",
      "  [-0.02550076 -0.04116795  0.03692475  0.03592353]\n",
      "  [ 0.04607505 -0.02227968 -0.02166769  0.04463879]]\n",
      "\n",
      " [[ 0.00935122 -0.01823239 -0.01778016 -0.04506478]\n",
      "  [-0.01417989 -0.00534748 -0.0290529   0.00897658]\n",
      "  [ 0.02389984  0.02206809 -0.00503595 -0.01765125]\n",
      "  [-0.00359341  0.04240408 -0.03554269  0.04958718]\n",
      "  [ 0.04607505 -0.02227968 -0.02166769  0.04463879]]\n",
      "\n",
      " [[ 0.00935122 -0.01823239 -0.01778016 -0.04506478]\n",
      "  [-0.01417989 -0.00534748 -0.0290529   0.00897658]\n",
      "  [-0.02972589 -0.02586786  0.02854559  0.03632262]\n",
      "  [-0.03096052  0.02522025 -0.02808404  0.0293151 ]\n",
      "  [-0.04234467  0.02327475 -0.03541576 -0.0288743 ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25796/2839805034.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
      "2021-09-03 01:29:21.928428: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-03 01:29:21.928655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.928946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2021-09-03 01:29:21.928984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-03 01:29:21.929017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-03 01:29:21.929034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-03 01:29:21.929049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-03 01:29:21.929063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-03 01:29:21.929078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-03 01:29:21.929092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-03 01:29:21.929107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-03 01:29:21.929181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.929463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.929682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-03 01:29:21.929973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.930204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2021-09-03 01:29:21.930224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-03 01:29:21.930242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-03 01:29:21.930256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-03 01:29:21.930269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-03 01:29:21.930283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-03 01:29:21.930296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-03 01:29:21.930310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-03 01:29:21.930323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-03 01:29:21.930391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.930670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.930903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-03 01:29:21.930936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-03 01:29:21.930943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-03 01:29:21.930949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-03 01:29:21.931054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.931340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:29:21.931568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 121 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)\n",
      "2021-09-03 01:29:21.931588: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# 위 과정 재도전\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 4차원의 워드벡터를 가정\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의 \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시퀀스 데이터를 다루는 RNN(Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except RuntimeError as e:\n",
    "#         # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델을 사용하여 텍스트 데이터 처리\n",
    "# input_shape = (None,) 모든차원의 데이터를 입력으로 받아들일 수 있음\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트를 처리하기 위해 RNN이 아니라 1-D Convolution Neural Network(1-D CNN)을 사용할 수도 있다.  \n",
    "이미지는 시퀀스 데이터가 아니다. 이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용된다.  \n",
    "그러므로 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용   \n",
    "이 방식도 텍스트를 처리하는 데 RNN 못지않은 효율, CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습속도도 훨씬 빠르게 진행된다는 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 간단히는 GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 생각할 수 있다. 이 방식은 전체 문장 중 가장 중요한 단 하나의 특징만을 추출해서 문장의 긍정/부정을 평가하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D 모델을 사용하여 텍스트 데이터 처리\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 1-D CNN과 RNN을 섞어 쓴다거나, FFN(FeedForword Network) 레이어만으로 구성하거나, Transformer 레이어를 쓰는 등 다양한 시도를 해볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성되어 있으며, 긍정은 1, 부정은 0의 라벨이 달려있다.  \n",
    "이 중 25000개가 훈련용 데이터, 나머지 25000개를 테스트 데이터로 사용하도록 지정되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/jin/anaconda3/envs/ssac/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/envs/ssac/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# word_index 가져오기\n",
    "# get_word_index() 자체적으로 만들어놓은 단어:번호로 된 사전 가져옴(10000까지)\n",
    "# 번호:단어로 바꿔줌\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "\n",
    "print(index_to_word[1])     # 'the' 가 출력 \n",
    "print(word_to_index['the'])  # 1 이 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
      "라벨:  1\n",
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n"
     ]
    }
   ],
   "source": [
    "# decoding\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다.'.format(np.sum(num_tokens < max_tokens)/len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        \n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       \n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "         14,   47,    8,   30,   31,    7,    4,  249,  108,    7,    4,\n",
       "       5974,   54,   61,  369,   13,   71,  149,   14,   22,  112,    4,\n",
       "       2401,  311,   12,   16, 3711,   33,   75,   43, 1829,  296,    4,\n",
       "         86,  320,   35,  534,   19,  263, 4821, 1301,    4, 1873,   33,\n",
       "         89,   78,   12,   66,   16,    4,  360,    7,    4,   58,  316,\n",
       "        334,   11,    4, 1716,   43,  645,  662,    8,  257,   85, 1200,\n",
       "         42, 1228, 2578,   83,   68, 3912,   15,   36,  165, 1539,  278,\n",
       "         36,   69,    2,  780,    8,  106,   14, 6905, 1338,   18,    6,\n",
       "         22,   12,  215,   28,  610,   40,    6,   87,  326,   23, 2300,\n",
       "         21,   23,   22,   12,  272,   40,   57,   31,   11,    4,   22,\n",
       "         47,    6, 2307,   51,    9,  170,   23,  595,  116,  595, 1352,\n",
       "         13,  191,   79,  638,   89,    2,   14,    9,    8,  106,  607,\n",
       "        624,   35,  534,    6,  227,    7,  129,  113], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 01:32:57.018235: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-03 01:32:57.018422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.018831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2021-09-03 01:32:57.018857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-03 01:32:57.018877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-03 01:32:57.018887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-03 01:32:57.018895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-03 01:32:57.018904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-03 01:32:57.018912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-03 01:32:57.018921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-03 01:32:57.018929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-03 01:32:57.018975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.019350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.019683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-03 01:32:57.019885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.020231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2021-09-03 01:32:57.020244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-03 01:32:57.020254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-03 01:32:57.020262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-03 01:32:57.020271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-03 01:32:57.020278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-03 01:32:57.020286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-03 01:32:57.020294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-03 01:32:57.020303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-03 01:32:57.020345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.020719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.021050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-03 01:32:57.021074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-03 01:32:57.021079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-03 01:32:57.021083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-03 01:32:57.021161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.021538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-03 01:32:57.021879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5094 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)\n",
      "2021-09-03 01:32:57.021893: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000 # 어휘사전의 크기입니다. (10000개의 단어)\n",
    "word_vector_dim = 16 # 워드벡터의 차원수(변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 01:33:13.400181: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-09-03 01:33:13.418820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3399905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 01:33:14.591973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-03 01:33:14.767037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 17s 32ms/step - loss: 0.6101 - accuracy: 0.6487 - val_loss: 0.3912 - val_accuracy: 0.8329\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.2739 - accuracy: 0.8991 - val_loss: 0.3062 - val_accuracy: 0.8780\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.1685 - accuracy: 0.9426 - val_loss: 0.3310 - val_accuracy: 0.8632\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.1369 - accuracy: 0.9540 - val_loss: 0.3609 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.0934 - accuracy: 0.9719 - val_loss: 0.4140 - val_accuracy: 0.8638\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0907 - accuracy: 0.9744 - val_loss: 0.4706 - val_accuracy: 0.8581\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.0825 - accuracy: 0.9733 - val_loss: 0.4613 - val_accuracy: 0.8578\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.5254 - val_accuracy: 0.8569\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0451 - accuracy: 0.9882 - val_loss: 0.5528 - val_accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.5969 - val_accuracy: 0.8585\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=epochs,\n",
    "                   batch_size=32, validation_data=(x_val, y_val),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 8s - loss: 0.6509 - accuracy: 0.8481\n",
      "[0.6509085297584534, 0.8481199741363525]\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(results)\n",
    "\n",
    "# 모델의 fitting 과정 중의 정보들이 history 변수에 저장\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 도식화 Training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# bo : 파란색\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b : 파란실선\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Validation accuracy\n",
    "plt.clf() # 그림을 초기화\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install gensim : 워드벡터를 다루는데 유용한 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 레이어 생성\n",
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape) # shape : (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 저장\n",
    "import os\n",
    "\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) # 몇개의 벡터를 얼마 사이즈로 기재할지\n",
    "# ?\n",
    "\n",
    "# 단어 갯수(에서 특수문자4개는 제외)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4, vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25942/3840502609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# gensim에서 제공하는 패키지를 이용하여 임베딩 파라미터를 word vector로 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'computer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/corpora/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[0;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/corpora/indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;31m# try to load fast, cythonized code if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/_matutils.pyx\u001b[0m in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "# gensim에서 제공하는 패키지를 이용하여 임베딩 파라미터를 word vector로 사용\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector\n",
    "\n",
    "# 단어 유사도 분석\n",
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "감성분류 태스크를 잠깐 학습한 것 만으로는 워드벡터가 유의미하게 학습되기 어려운 것 같다. \n",
    " 이 정도의 훈련 데이터로는 워드벡터를 정교하게 학습시키기 어렵다고 한다. 따라서 구글에서 제공하는 Word2Vec라는 사전 학습된 워드 임베딩 모델을 활용해보자.  \n",
    " https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25942/2224838277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mword2vec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mworf2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKetedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'computer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/corpora/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[0;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/corpora/indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;31m# try to load fast, cythonized code if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssac/lib/python3.8/site-packages/gensim/_matutils.pyx\u001b[0m in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "worf2vec = KetedVectors.load_word2vec_format(word2vec_path, binary=True, limit=None)\n",
    "vector = word2vec['computer']\n",
    "vector # 300dim의 워드 벡터, limit으로 조건주어 로딩가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 유사도 분석\n",
    "word2vec.similar_by_word('love')\n",
    "\n",
    "# 임베딩 레이어 변경\n",
    "vocab_size = 10000 # 어휘사전의 크기(10000개의 단어)\n",
    "word_vector_dim = 300 # 워드 벡터의 차원수 (변경가능한 하이퍼 파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피\n",
    "for i in range(4, vocab_size):\n",
    "    if  index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25942/132722912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.add(keras.layers.Embedding(vocab_size, word_vector_dim,\n\u001b[0;32m----> 7\u001b[0;31m                                 \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                                 input_length=maxlen, trainable=True))\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# trainable을 True로 주면 Finetuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 설계\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim,\n",
    "                                embeddings_initializer=Constant(embedding_matrix),\n",
    "                                input_length=maxlen, trainable=True))\n",
    "# trainable을 True로 주면 Finetuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
