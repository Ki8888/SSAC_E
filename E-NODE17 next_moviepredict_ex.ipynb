{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 - Movielens 영화 SBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Movielens 1M Dataset을 기반으로, Session based Recommendation 시스템을 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) wget으로 데이터 다운로드\n",
    "# $ wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "\n",
    "# 2) 다운받은 데이터를 작업디렉토리로 이동\n",
    "# $ mv ml-1m.zip ~/aiffel/yoochoose-data\n",
    "\n",
    "# 3) 압축 해제\n",
    "# $ cd ~/aiffel/yoochoose-data && unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "These files contain 1,000,209 anonymous ratings of approximately 3,900 movies \n",
      "\n",
      "made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
      "\n",
      "\n",
      "\n",
      "USAGE LICENSE\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "Neither the University of Minnesota nor any of the researchers\n",
      "\n",
      "involved can guarantee the correctness of the data, its suitability\n",
      "\n",
      "for any particular purpose, or the validity of results based on the\n",
      "\n",
      "use of the data set.  The data set may be used for any research\n",
      "\n",
      "purposes under the following conditions:\n",
      "\n",
      "\n",
      "\n",
      "     * The user may not state or imply any endorsement from the\n",
      "\n",
      "       University of Minnesota or the GroupLens Research Group.\n",
      "\n",
      "\n",
      "\n",
      "     * The user must acknowledge the use of the data set in\n",
      "\n",
      "       publications resulting from the use of the data set\n",
      "\n",
      "       (see below for citation information).\n",
      "\n",
      "\n",
      "\n",
      "     * The user may not redistribute the data without separate\n",
      "\n",
      "       permission.\n",
      "\n",
      "\n",
      "\n",
      "     * The user may not use this information for any commercial or\n",
      "\n",
      "       revenue-bearing purposes without first obtaining permission\n",
      "\n",
      "       from a faculty member of the GroupLens Research Project at the\n",
      "\n",
      "       University of Minnesota.\n",
      "\n",
      "\n",
      "\n",
      "If you have any further questions or comments, please contact GroupLens\n",
      "\n",
      "<grouplens-info@cs.umn.edu>. \n",
      "\n",
      "\n",
      "\n",
      "CITATION\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "To acknowledge use of the dataset in publications, please cite the following\n",
      "\n",
      "paper:\n",
      "\n",
      "\n",
      "\n",
      "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History\n",
      "\n",
      "and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4,\n",
      "\n",
      "Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ACKNOWLEDGEMENTS\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "Thanks to Shyong Lam and Jon Herlocker for cleaning up and generating the data\n",
      "\n",
      "set.\n",
      "\n",
      "\n",
      "\n",
      "FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "The GroupLens Research Project is a research group in the Department of \n",
      "\n",
      "Computer Science and Engineering at the University of Minnesota. Members of \n",
      "\n",
      "the GroupLens Research Project are involved in many research projects related \n",
      "\n",
      "to the fields of information filtering, collaborative filtering, and \n",
      "\n",
      "recommender systems. The project is lead by professors John Riedl and Joseph \n",
      "\n",
      "Konstan. The project began to explore automated collaborative filtering in \n",
      "\n",
      "1992, but is most well known for its world wide trial of an automated \n",
      "\n",
      "collaborative filtering system for Usenet news in 1996. Since then the project \n",
      "\n",
      "has expanded its scope to research overall information filtering solutions, \n",
      "\n",
      "integrating in content-based methods as well as improving current collaborative \n",
      "\n",
      "filtering technology.\n",
      "\n",
      "\n",
      "\n",
      "Further information on the GroupLens Research project, including research \n",
      "\n",
      "publications, can be found at the following web site:\n",
      "\n",
      "        \n",
      "\n",
      "        http://www.grouplens.org/\n",
      "\n",
      "\n",
      "\n",
      "GroupLens Research currently operates a movie recommender based on \n",
      "\n",
      "collaborative filtering:\n",
      "\n",
      "\n",
      "\n",
      "        http://www.movielens.org/\n",
      "\n",
      "\n",
      "\n",
      "RATINGS FILE DESCRIPTION\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "All ratings are contained in the file \"ratings.dat\" and are in the\n",
      "\n",
      "following format:\n",
      "\n",
      "\n",
      "\n",
      "UserID::MovieID::Rating::Timestamp\n",
      "\n",
      "\n",
      "\n",
      "- UserIDs range between 1 and 6040 \n",
      "\n",
      "- MovieIDs range between 1 and 3952\n",
      "\n",
      "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
      "\n",
      "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
      "\n",
      "- Each user has at least 20 ratings\n",
      "\n",
      "\n",
      "\n",
      "USERS FILE DESCRIPTION\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "User information is in the file \"users.dat\" and is in the following\n",
      "\n",
      "format:\n",
      "\n",
      "\n",
      "\n",
      "UserID::Gender::Age::Occupation::Zip-code\n",
      "\n",
      "\n",
      "\n",
      "All demographic information is provided voluntarily by the users and is\n",
      "\n",
      "not checked for accuracy.  Only users who have provided some demographic\n",
      "\n",
      "information are included in this data set.\n",
      "\n",
      "\n",
      "\n",
      "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
      "\n",
      "- Age is chosen from the following ranges:\n",
      "\n",
      "\n",
      "\n",
      "\t*  1:  \"Under 18\"\n",
      "\n",
      "\t* 18:  \"18-24\"\n",
      "\n",
      "\t* 25:  \"25-34\"\n",
      "\n",
      "\t* 35:  \"35-44\"\n",
      "\n",
      "\t* 45:  \"45-49\"\n",
      "\n",
      "\t* 50:  \"50-55\"\n",
      "\n",
      "\t* 56:  \"56+\"\n",
      "\n",
      "\n",
      "\n",
      "- Occupation is chosen from the following choices:\n",
      "\n",
      "\n",
      "\n",
      "\t*  0:  \"other\" or not specified\n",
      "\n",
      "\t*  1:  \"academic/educator\"\n",
      "\n",
      "\t*  2:  \"artist\"\n",
      "\n",
      "\t*  3:  \"clerical/admin\"\n",
      "\n",
      "\t*  4:  \"college/grad student\"\n",
      "\n",
      "\t*  5:  \"customer service\"\n",
      "\n",
      "\t*  6:  \"doctor/health care\"\n",
      "\n",
      "\t*  7:  \"executive/managerial\"\n",
      "\n",
      "\t*  8:  \"farmer\"\n",
      "\n",
      "\t*  9:  \"homemaker\"\n",
      "\n",
      "\t* 10:  \"K-12 student\"\n",
      "\n",
      "\t* 11:  \"lawyer\"\n",
      "\n",
      "\t* 12:  \"programmer\"\n",
      "\n",
      "\t* 13:  \"retired\"\n",
      "\n",
      "\t* 14:  \"sales/marketing\"\n",
      "\n",
      "\t* 15:  \"scientist\"\n",
      "\n",
      "\t* 16:  \"self-employed\"\n",
      "\n",
      "\t* 17:  \"technician/engineer\"\n",
      "\n",
      "\t* 18:  \"tradesman/craftsman\"\n",
      "\n",
      "\t* 19:  \"unemployed\"\n",
      "\n",
      "\t* 20:  \"writer\"\n",
      "\n",
      "\n",
      "\n",
      "MOVIES FILE DESCRIPTION\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "Movie information is in the file \"movies.dat\" and is in the following\n",
      "\n",
      "format:\n",
      "\n",
      "\n",
      "\n",
      "MovieID::Title::Genres\n",
      "\n",
      "\n",
      "\n",
      "- Titles are identical to titles provided by the IMDB (including\n",
      "\n",
      "year of release)\n",
      "\n",
      "- Genres are pipe-separated and are selected from the following genres:\n",
      "\n",
      "\n",
      "\n",
      "\t* Action\n",
      "\n",
      "\t* Adventure\n",
      "\n",
      "\t* Animation\n",
      "\n",
      "\t* Children's\n",
      "\n",
      "\t* Comedy\n",
      "\n",
      "\t* Crime\n",
      "\n",
      "\t* Documentary\n",
      "\n",
      "\t* Drama\n",
      "\n",
      "\t* Fantasy\n",
      "\n",
      "\t* Film-Noir\n",
      "\n",
      "\t* Horror\n",
      "\n",
      "\t* Musical\n",
      "\n",
      "\t* Mystery\n",
      "\n",
      "\t* Romance\n",
      "\n",
      "\t* Sci-Fi\n",
      "\n",
      "\t* Thriller\n",
      "\n",
      "\t* War\n",
      "\n",
      "\t* Western\n",
      "\n",
      "\n",
      "\n",
      "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
      "\n",
      "entries and/or test entries\n",
      "\n",
      "- Movies are mostly entered by hand, so errors and inconsistencies may exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 설명(README)를 읽어 봅니다. \n",
    "import os\n",
    "f = open(os.getenv('HOME')+'/aiffel/yoochoose-data/ml-1m/README', 'r')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>997454429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>997454486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating       Time\n",
       "31            1    3186       4  978300019\n",
       "22            1    1270       5  978300055\n",
       "27            1    1721       4  978300055\n",
       "37            1    1022       5  978300055\n",
       "24            1    2340       3  978300103\n",
       "...         ...     ...     ...        ...\n",
       "1000019    6040    2917       4  997454429\n",
       "999988     6040    1921       4  997454464\n",
       "1000172    6040    1784       3  997454464\n",
       "1000167    6040     161       3  997454486\n",
       "1000042    6040    1221       4  998315055\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(os.getenv('HOME')+'/aiffel/yoochoose-data/ml-1m') \n",
    "train_path = data_path / 'ratings.dat'\n",
    "\n",
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n",
    "    return data\n",
    "\n",
    "data = load_data(train_path, None)\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여기서 이전 실습내역과 가장 크게 다른 부분은 바로 SessionID 대신 UserID 항목이 들어갔다는 점입니다. 이 데이터셋은 명확한 1회 세션의 SessionID를 포함하지 않고 있습니다. 그래서 이번에는 UserID가 SessionID 역할을 해야 합니다.\n",
    "\n",
    "* Rating 정보가 포함되어 있습니다. 이전 실습내역에서는 이런 항목이 포함되어 있지 않았으므로, 무시하고 제외할 수 있습니다. 하지만, 직전에 봤던 영화가 맘에 들었는지 여부가 비슷한 영화를 더 고르게 하는 것과 상관이 있을 수도 있습니다. 아울러, Rating이 낮은 데이터를 어떻게 처리할지도 고민해야 합니다.\n",
    "\n",
    "* Time 항목에는 UTC time 가 포함되어, 1970년 1월 1일부터 경과된 초단위 시간이 기재되어 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터의 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId      6040\n",
       "ItemId      3706\n",
       "Rating         5\n",
       "Time      458455\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId    0\n",
       "ItemId    0\n",
       "Rating    0\n",
       "Time      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rating'][data['Rating']<3].value_counts().sum()\n",
    "# 100만개중 42만개가 3점이하 >>미사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226310"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rating'][data['Rating']==5].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Rating']>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836473</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>997454429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836474</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836475</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836476</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>997454486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836477</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserId  ItemId  Rating       Time\n",
       "0            1    3186       4  978300019\n",
       "1            1    1270       5  978300055\n",
       "2            1    1721       4  978300055\n",
       "3            1    1022       5  978300055\n",
       "4            1    2340       3  978300103\n",
       "...        ...     ...     ...        ...\n",
       "836473    6040    2917       4  997454429\n",
       "836474    6040    1921       4  997454464\n",
       "836475    6040    1784       3  997454464\n",
       "836476    6040     161       3  997454486\n",
       "836477    6040    1221       4  998315055\n",
       "\n",
       "[836478 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 접속시간대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836478\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "Time2 = []\n",
    "for i in range(len(data['Time'])):\n",
    "    timestamp = datetime.datetime.fromtimestamp(i)\n",
    "    #print(timestamp)\n",
    "     \n",
    "    Time2.append(timestamp)\n",
    "print(len(Time2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time2 = pd.Series(Time2, name='Time2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data,Time2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 836478 entries, 0 to 836477\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   UserId  836478 non-null  int32         \n",
      " 1   ItemId  836478 non-null  int32         \n",
      " 2   Rating  836478 non-null  int32         \n",
      " 3   Time    836478 non-null  int64         \n",
      " 4   Time2   836478 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int32(3), int64(1)\n",
      "memory usage: 22.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970-01-01 09:00:00\n",
      "1970-01-11 01:21:17\n"
     ]
    }
   ],
   "source": [
    "oldest, latest = data['Time2'].min(), data['Time2'].max()\n",
    "print(oldest) \n",
    "print(latest)\n",
    "# 70년도의 10일치 데이터??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId\n",
       "1        53\n",
       "2       116\n",
       "3        46\n",
       "4        19\n",
       "5       143\n",
       "       ... \n",
       "6036    708\n",
       "6037    189\n",
       "6038     18\n",
       "6039    119\n",
       "6040    276\n",
       "Length: 6039, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length = data.groupby('UserId').size()\n",
    "user_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.51266766020865"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한유저가 몇개의 영화에 평점을 줬는가?\n",
    "# 10일간의 데이터에서 마지막1일 테스트 그전1일 평가 나머지 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time2'].max()\n",
    "    user_last_time = data.groupby('UserId')['Time2'].max()\n",
    "    user_in_train = user_last_time[user_last_time < final_time - dt.timedelta(n_days)].index\n",
    "    user_in_test = user_last_time[user_last_time >= final_time - dt.timedelta(n_days)].index\n",
    "\n",
    "    before_date = data[data['UserId'].isin(user_in_train)]\n",
    "    after_date = data[data['UserId'].isin(user_in_test)]\n",
    "    after_date = after_date[after_date['ItemId'].isin(before_date['ItemId'])]\n",
    "    return before_date, after_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, test = split_by_date(data, n_days=1)\n",
    "tr, val = split_by_date(tr, n_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data에 대한 정보를 살펴봅니다.\n",
    "def stats_info(data: pd.DataFrame, status: str):\n",
    "    print(f'* {status} Set Stats Info\\n'\n",
    "          f'\\t Events: {len(data)}\\n'\n",
    "          f'\\t Sessions: {data[\"UserId\"].nunique()}\\n'\n",
    "          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n",
    "          f'\\t First Time : {data[\"Time2\"].min()}\\n'\n",
    "          f'\\t Last Time : {data[\"Time2\"].max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train Set Stats Info\n",
      "\t Events: 663519\n",
      "\t Sessions: 4765\n",
      "\t Items: 3597\n",
      "\t First Time : 1970-01-01 09:00:00\n",
      "\t Last Time : 1970-01-09 01:18:38\n",
      "\n",
      "* valid Set Stats Info\n",
      "\t Events: 86417\n",
      "\t Sessions: 659\n",
      "\t Items: 3122\n",
      "\t First Time : 1970-01-09 01:18:39\n",
      "\t Last Time : 1970-01-10 01:19:19\n",
      "\n",
      "* test Set Stats Info\n",
      "\t Events: 86507\n",
      "\t Sessions: 615\n",
      "\t Items: 3055\n",
      "\t First Time : 1970-01-10 01:19:20\n",
      "\t Last Time : 1970-01-11 01:21:17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_info(tr, 'train')\n",
    "stats_info(val, 'valid')\n",
    "stats_info(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에 없는 아이템이 val, test기간에 생길 수 있으므로 train data를 기준으로 인덱싱합니다.\n",
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  # id2idx에 없는 아이템은 모르는 값(-1) 처리 해줍니다.\n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = data_path / 'processed'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tr.to_pickle(save_path / 'train.pkl')\n",
    "val.to_pickle(save_path / 'valid.pkl')\n",
    "test.to_pickle(save_path / 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 미니배치구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 주어지면 세션이 시작되는 인덱스를 담는 값과 세션을 새로 인덱싱한 값을 갖는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()\n",
    "        self.user_idx = np.arange(self.df['UserId'].nunique())  # indexing to SessionId\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        \"\"\"\n",
    "        Return the indexes of the first click of each session IDs,\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df['UserId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('UserId').size().cumsum()\n",
    "        return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>Time2</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "      <td>1970-01-01 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1970-01-01 09:00:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1970-01-01 09:00:02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1970-01-01 09:00:03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "      <td>1970-01-01 09:00:04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Rating       Time               Time2  item_idx\n",
       "0       1    3186       4  978300019 1970-01-01 09:00:00         0\n",
       "1       1    1270       5  978300055 1970-01-01 09:00:01         1\n",
       "2       1    1721       4  978300055 1970-01-01 09:00:02         2\n",
       "3       1    1022       5  978300055 1970-01-01 09:00:03         3\n",
       "4       1    2340       3  978300103 1970-01-01 09:00:04         4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset = UserDataset(tr)\n",
    "tr_dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     53,    169, ..., 663235, 663485, 663519], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 세션이 시작된 인덱스\n",
    "tr_dataset.click_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 4762, 4763, 4764])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 세션을 인덱싱한 np.array\n",
    "tr_dataset.user_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SessionDataset 객체를 받아서 Session-Parallel mini-batch를 만드는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataLoader:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: UserDataset, batch_size=50):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "        Yields:\n",
    "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인\n",
    "        \"\"\"\n",
    "        start : Index Where Session Start\n",
    "        end : Index Where Session End\n",
    "        mask : indicator for the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        while not finished:\n",
    "            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n",
    "            for i in range(min_len):\n",
    "                # Build inputs & targets\n",
    "                inp = self.dataset.df['item_idx'].values[start + i]\n",
    "                target = self.dataset.df['item_idx'].values[start + i + 1]\n",
    "                yield inp, target, mask\n",
    "\n",
    "            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n",
    "\n",
    "    def initialize(self):\n",
    "        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n",
    "        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n",
    "        start = self.dataset.click_offsets[self.dataset.user_idx[first_iters]-1]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "        end = self.dataset.click_offsets[self.dataset.user_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n",
    "        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):  \n",
    "        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n",
    "        \n",
    "        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n",
    "        mask = np.arange(self.batch_size)[(end - start) == 1]  \n",
    "        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n",
    "\n",
    "        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n",
    "            new_session = last_session + i  \n",
    "            if new_session > self.dataset.user_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n",
    "                finished = True\n",
    "                break\n",
    "            # update the next starting/ending point\n",
    "            start[idx] = self.dataset.click_offsets[self.dataset.user_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n",
    "            end[idx] = self.dataset.click_offsets[self.dataset.user_idx[new_session] + 1]\n",
    "\n",
    "        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n",
    "        return start, end, mask, last_session, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>Time2</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "      <td>1970-01-01 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1970-01-01 09:00:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1970-01-01 09:00:02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>1970-01-01 09:00:03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "      <td>1970-01-01 09:00:04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Rating       Time               Time2  item_idx\n",
       "0       1    3186       4  978300019 1970-01-01 09:00:00         0\n",
       "1       1    1270       5  978300055 1970-01-01 09:00:01         1\n",
       "2       1    1721       4  978300055 1970-01-01 09:00:02         2\n",
       "3       1    1022       5  978300055 1970-01-01 09:00:03         3\n",
       "4       1    2340       3  978300103 1970-01-01 09:00:04         4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data_loader = UserDataLoader(tr_dataset, batch_size=4)\n",
    "tr_dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ex = iter(tr_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Item Idx are : [201  52 101 192]\n",
      "Label Item Idx are :       [ 12  53 102  16]\n",
      "Previous Masked Input Idx are [0]\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, mask =  next(iter_ex)\n",
    "print(f'Model Input Item Idx are : {inputs}')\n",
    "print(f'Label Item Idx are : {\"\":5} {labels}')\n",
    "print(f'Previous Masked Input Idx are {mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* eval metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args):\n",
    "    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n",
    "    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n",
    "    dropout = Dropout(args.drop_rate)(gru)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=[predictions])\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hyper-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_sessions = tr['UserId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k\n",
    "\n",
    "args = Args(tr, val, test, batch_size=2048, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(2048, 1, 3597)]         0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(2048, 50), (2048, 50)]  547350    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (2048, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (2048, 3597)              183447    \n",
      "=================================================================\n",
      "Total params: 730,797\n",
      "Trainable params: 730,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 셋으로 학습하면서 valid 셋으로 검증합니다.\n",
    "def train_model(model, args):\n",
    "    train_dataset = UserDataset(args.tr)\n",
    "    train_loader = UserDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total_step = len(args.tr) - args.tr['UserId'].nunique()\n",
    "        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n",
    "        for feat, target, mask in tr_loader:\n",
    "            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. \n",
    "\n",
    "            input_ohe = to_categorical(feat, num_classes=args.num_items)\n",
    "            input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "            target_ohe = to_categorical(target, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n",
    "\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n",
    "\n",
    "        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n",
    "\n",
    "\n",
    "def reset_hidden_states(model, mask):\n",
    "    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n",
    "    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n",
    "    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n",
    "        hidden_states[elt, :] = 0  # parameter를 초기화 \n",
    "    gru_layer.reset_states(states=hidden_states)\n",
    "\n",
    "\n",
    "def get_metrics(data, model, args, k: int):  \n",
    "                                             #  mrr, recall을 구하는 라인잇다.\n",
    "    dataset = UserDataset(data)\n",
    "    loader = UserDataLoader(dataset, batch_size=args.batch_size)\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    total_step = len(data) - data['UserId'].nunique()\n",
    "    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n",
    "        reset_hidden_states(model, mask)\n",
    "        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n",
    "        input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')  # softmax 값이 큰 순서대로 sorting \n",
    "\n",
    "        length = len(inputs)\n",
    "        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "\n",
    "    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 217188it [2:41:11, 22.46it/s, accuracy=0.123, train_loss=4.94]                       \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-feeb9149d92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-9c306f76966a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtarget_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtr_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train :216500it, 2:40:00 accu=0.12 train_loss = 4.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, args, test):\n",
    "    test_recall, test_mrr = get_metrics(test, model, args, 20)\n",
    "    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n",
    "    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")\n",
    "\n",
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''노드에서 sessionid 기준으로 item들을 시간대별로 정렬해서 병렬처리 한 방식과 달리\n",
    "UserId기준으로 작업을 했더니 전처리가 잘못되었거나, 모델이 잘못되었는지 accuracy가 매우 낮게 나오는 현상이 발생\n",
    "GRU모델의 기본적인 개념을 맞게 이해했는지 모르겠으나, 이를 코드로 구현하는데 매우 어려워서 거의 그대로 필사하였고, \n",
    "어느부분을 수정해야하는지에 대한 내용도 어려움'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
